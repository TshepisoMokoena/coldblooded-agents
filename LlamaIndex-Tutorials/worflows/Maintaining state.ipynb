{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bc7d9029-406a-4ec2-a31d-6803d7d2648f",
   "metadata": {},
   "source": [
    "# ðŸ“¢ Disclaimer\n",
    "\n",
    "This notebook contains material copied verbatim from the [LlamaIndex documentation](https://www.llamaindex.ai/)  \n",
    "and was created with the assistance of ChatGPT.  \n",
    "\n",
    "It is intended for educational purposes only.  \n",
    "All copyrights and credits belong to the LlamaIndex team and their respective authors.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae4a82cb-c3ae-4d53-9655-6e6c2da2d124",
   "metadata": {},
   "source": [
    "# Maintaining state\n",
    "\n",
    "In our examples so far, we have passed data from step to step using properties of custom events. This is a powerful way to pass data around, but it has limitations. For example, if you want to pass data between steps that are not directly connected, you need to pass the data through all the steps in between. This can make your code harder to read and maintain.\n",
    "\n",
    "To avoid this pitfall, we have a `Context` object available to every step in the workflow. To use it, declare an argument of type `Context` to your step."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78fd0070-b179-4f42-8224-c866a2426d1e",
   "metadata": {},
   "source": [
    "Now we define a `start` event that checks if data has been loaded into the context. If not, it returns a `SetupEvent` which triggers `setup` that loads the data and loops back to start."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "95dbaef3-a31b-41a1-bc37-fae818dd7626",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.workflow import (\n",
    "    StartEvent,\n",
    "    StopEvent,\n",
    "    Workflow,\n",
    "    step,\n",
    "    Event,\n",
    "    Context,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d8527d26-1ac6-43bb-b9d0-d64392a9b2ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Need to load data\n",
      "Data is  [1, 2, 3]\n",
      "[1, 2, 3]\n"
     ]
    }
   ],
   "source": [
    "class SetupEvent(Event):\n",
    "    query: str\n",
    "\n",
    "\n",
    "class StepTwoEvent(Event):\n",
    "    query: str\n",
    "\n",
    "\n",
    "class StatefulFlow(Workflow):\n",
    "    @step\n",
    "    async def start(\n",
    "        self, ctx: Context, ev: StartEvent\n",
    "    ) -> SetupEvent | StepTwoEvent:\n",
    "        db = await ctx.get(\"some_database\", default=None)\n",
    "        if db is None:\n",
    "            print(\"Need to load data\")\n",
    "            return SetupEvent(query=ev.query)\n",
    "\n",
    "        # do something with the query\n",
    "        return StepTwoEvent(query=ev.query)\n",
    "\n",
    "    @step\n",
    "    async def setup(self, ctx: Context, ev: SetupEvent) -> StartEvent:\n",
    "        # load data\n",
    "        await ctx.set(\"some_database\", [1, 2, 3])\n",
    "        return StartEvent(query=ev.query)\n",
    "\n",
    "    @step\n",
    "    async def step_two(self, ctx: Context, ev: StepTwoEvent) -> StopEvent:\n",
    "        # do something with the data\n",
    "        print(\"Data is \", await ctx.get(\"some_database\"))\n",
    "    \n",
    "        return StopEvent(result=await ctx.get(\"some_database\"))\n",
    "\n",
    "\n",
    "w = StatefulFlow(timeout=10, verbose=False)\n",
    "result = await w.run(query=\"Some query\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c67f9127-f914-44e5-8975-df904bfb0baa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maintaining_state.html\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "gio: file:///home/tshepiso/workspace/coldblooded-agents/LlamaIndex-Tutorials/worflows/Maintaining_state.html: Failed to find default application for content type â€˜text/htmlâ€™\n"
     ]
    }
   ],
   "source": [
    "from llama_index.utils.workflow import draw_all_possible_flows\n",
    "\n",
    "draw_all_possible_flows(StatefulFlow, filename=\"Maintaining_state.html\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
