{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "47b67742-531f-4cb0-accb-1594d0f5e925",
   "metadata": {},
   "source": [
    "# ðŸ“¢ Disclaimer\n",
    "\n",
    "This notebook contains material copied verbatim from the [LlamaIndex documentation](https://www.llamaindex.ai/)  \n",
    "and was created with the assistance of ChatGPT.  \n",
    "\n",
    "It is intended for educational purposes only.  \n",
    "All copyrights and credits belong to the LlamaIndex team and their respective authors.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0e4473f-8f51-4004-9d01-6dd169e5b93f",
   "metadata": {},
   "source": [
    "# Observability\n",
    "\n",
    "Debugging is essential to any application development, and Workflows provide you a number of ways to do that."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9013ac07-4a95-46fc-a2df-8f08f9db725e",
   "metadata": {},
   "source": [
    "## Visualization\n",
    "\n",
    "The simplest form of debugging is visualization, which we've already used extensively in this tutorial. You can visualize your workflow at any time by running the following code:\n",
    "\n",
    "## Verbose mode\n",
    "\n",
    "When running any workflow you can always pass `verbose=True`. This will output the name of each step as it's executed, and whether and which type of event it returns. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "df207676-988b-45b6-823b-47eca655038e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.workflow import (\n",
    "    StartEvent,\n",
    "    StopEvent,\n",
    "    Workflow,\n",
    "    step,\n",
    "    Event,\n",
    "    Context,\n",
    ")\n",
    "\n",
    "import asyncio\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "278fe5f1-39a7-4d6d-97b3-423fa1ccbdc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running step start\n",
      "Step start produced no event\n",
      "Running step step_two\n",
      "Running query  Query 1\n",
      "Running step step_two\n",
      "Running query  Query 2\n",
      "Running step step_two\n",
      "Running query  Query 3\n",
      "Step step_two produced event StepThreeEvent\n",
      "Running step step_three\n",
      "Step step_three produced no event\n",
      "Step step_two produced event StepThreeEvent\n",
      "Running step step_three\n",
      "Step step_three produced no event\n",
      "Step step_two produced event StepThreeEvent\n",
      "Running step step_three\n",
      "[StepThreeEvent(result='Query 1'), StepThreeEvent(result='Query 3'), StepThreeEvent(result='Query 2')]\n",
      "Step step_three produced event StopEvent\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "class StepTwoEvent(Event):\n",
    "    query: str\n",
    "\n",
    "class StepThreeEvent(Event):\n",
    "    result: str\n",
    "\n",
    "class ConcurrentFlow(Workflow):\n",
    "    @step\n",
    "    async def start(self, ctx: Context, ev: StartEvent) -> StepTwoEvent:\n",
    "        ctx.send_event(StepTwoEvent(query=\"Query 1\"))\n",
    "        ctx.send_event(StepTwoEvent(query=\"Query 2\"))\n",
    "        ctx.send_event(StepTwoEvent(query=\"Query 3\"))\n",
    "\n",
    "    @step(num_workers=4)\n",
    "    async def step_two(self, ctx: Context, ev: StepTwoEvent) -> StepThreeEvent:\n",
    "        print(\"Running query \", ev.query)\n",
    "        await asyncio.sleep(random.randint(1, 5))\n",
    "        return StepThreeEvent(result=ev.query)\n",
    "\n",
    "    @step\n",
    "    async def step_three(self, ctx: Context, ev: StepThreeEvent) -> StopEvent:\n",
    "        # wait until we receive 3 events\n",
    "        result = ctx.collect_events(ev, [StepThreeEvent] * 3)\n",
    "        if result is None:\n",
    "            return None\n",
    "\n",
    "        # do something with all 3 results together\n",
    "        print(result)\n",
    "        return StopEvent(result=\"Done\")\n",
    "\n",
    "w = ConcurrentFlow(timeout=300, verbose=True)\n",
    "handler = await w.run()  \n",
    "print(handler)\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32217d38-37ed-488d-8b83-85971aa53815",
   "metadata": {},
   "source": [
    "## Stepwise execution\n",
    "\n",
    "In a notebook environment it can be helpful to run a workflow step by step. You can do this by calling `run_step` on the handler object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cad77911-773b-47c8-a51d-53cfee1ae028",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running step start\n",
      "Step start produced no event\n",
      "Running step step_two\n",
      "Running query  Query 1\n",
      "Running step step_two\n",
      "Running query  Query 2\n",
      "Running step step_two\n",
      "Running query  Query 3\n",
      "Running step step_two\n",
      "Running query  Query 1\n",
      "Step step_two produced event StepThreeEvent\n",
      "Step step_two produced event StepThreeEvent\n",
      "Step step_two produced event StepThreeEvent\n",
      "Step step_two produced event StepThreeEvent\n",
      "Running step step_three\n",
      "Step step_three produced no event\n",
      "Running step step_two\n",
      "Running query  Query 2\n",
      "Step step_two produced event StepThreeEvent\n",
      "Running step step_three\n",
      "Step step_three produced no event\n",
      "Running step step_two\n",
      "Running query  Query 3\n"
     ]
    }
   ],
   "source": [
    "w = ConcurrentFlow(timeout=10, verbose=True)\n",
    "handler = w.run(stepwise=True)\n",
    "\n",
    "# Each time we call `run_step`, the workflow will advance and return all the events\n",
    "# that were produced in the last step. This events need to be manually propagated\n",
    "# for the workflow to keep going (we assign them to `produced_events` with the := operator).\n",
    "while produced_events := await handler.run_step():\n",
    "    # If we're here, it means there's at least an event we need to propagate,\n",
    "    # let's do it with `send_event`\n",
    "    for ev in produced_events:\n",
    "        handler.ctx.send_event(ev)\n",
    "\n",
    "# If we're here, it means the workflow execution completed, and\n",
    "# we can now access the final result.\n",
    "result = await handler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45b7e8c5-b1ab-4ab2-b8e0-ab2ffefe531b",
   "metadata": {},
   "source": [
    "You can call run_step multiple times to step through the workflow one step at a time.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b9fa872-de4d-43b6-b085-c04790d5e798",
   "metadata": {},
   "source": [
    "## Visualizing most recent execution\n",
    "\n",
    "If you're running a workflow step by step, or you have just executed a workflow with branching, you can get the visualizer to draw only exactly which steps just executed using `draw_most_recent_execution`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05f7fe5f-3ea4-474b-9546-fc98c559e6a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.utils.workflow import draw_most_recent_execution\n",
    "\n",
    "draw_most_recent_execution(w, filename=\"last_execution.html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75e81095-8c27-4d17-8431-3807f92f7e37",
   "metadata": {},
   "source": [
    "Note that instead of passing the class name you are passing the instance of the workflow, `w`.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
